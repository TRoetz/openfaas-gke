apiVersion: v1
kind: Service
metadata:
  name: faas-netesd
  labels:
    app: faas-netesd
spec:
  type: NodePort
  ports:
    - port: 8080
      protocol: TCP
      targetPort: 8080
      nodePort: 31111
  selector:
    app: faas-netesd
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: faas-controller
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: faas-netesd
spec:
  replicas: 1
  selector:
    matchLabels:
      app: faas-netesd
  template:
    metadata:
      labels:
        app: faas-netesd
    spec:
      serviceAccountName: faas-controller
      containers:
      - name: faas-netesd
        image: functions/faas-netesd:0.3.1
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          protocol: TCP
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: faas-controller
rules:
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
- apiGroups:
  - extensions
  resources:
  - deployments
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: faas-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: faas-controller
subjects:
- kind: ServiceAccount
  name: faas-controller
  namespace: default
---
apiVersion: v1
kind: Service
metadata:
  name: gateway
  labels:
    app: gateway
spec:
  type: NodePort
  ports:
    - port: 8080
      protocol: TCP
      targetPort: 8080
      nodePort: 31112
  selector:
    app: gateway
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: gateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gateway
  template:
    metadata:
      labels:
        app: gateway
    spec:
      containers:
      - name: gateway
        image: functions/gateway:0.6.6-beta
        imagePullPolicy: Always
        env:
        - name: functions_provider_url
          value: "http://faas-netesd.default.svc.cluster.local:8080/"
        ports:
        - containerPort: 8080
          protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  labels:
    app: prometheus
spec:
  type: NodePort
  ports:
    - port: 9090
      protocol: TCP
      targetPort: 9090
      nodePort: 31119
  selector:
    app: prometheus
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v1.8.1
        command: ["prometheus","-config.file=/etc/prometheus/prometheus.yml", "-storage.local.path=/prometheus", "--alertmanager.url=http://alertmanager.default:9093"]
        imagePullPolicy: Always
        ports:
        - containerPort: 9090
          protocol: TCP
        volumeMounts:
        - mountPath: /etc/prometheus/prometheus.yml
          name: prometheus-config
          subPath: prometheus.yml
        - mountPath: /etc/prometheus/alert.rules
          name: prometheus-config
          subPath: alert.rules
      volumes:
        - name: prometheus-config
          configMap:
            name: prometheus-config
            items:
              - key: prometheus.yml
                path: prometheus.yml
                mode: 0644
              - key: alert.rules
                path: alert.rules
                mode: 0644
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  labels:
    app: alertmanager
spec:
  type: NodePort
  ports:
    - port: 9093
      protocol: TCP
      targetPort: 9093
      nodePort: 31113
  selector:
    app: alertmanager
---
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: alertmanager
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.9.1
        imagePullPolicy: Always
        command: ["/bin/alertmanager","-config.file=/alertmanager.yml", "-storage.path=/alertmanager"]
        ports:
        - containerPort: 9003
          protocol: TCP
        volumeMounts:
        - mountPath: /alertmanager.yml
          name: alertmanager-config
          subPath: alertmanager.yml
      volumes:
        - name: alertmanager-config
          configMap:
            name: alertmanager-config
            items:
              - key: alertmanager.yml
                path: alertmanager.yml
                mode: 0644
---
kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    app: prometheus
  name: prometheus-config
data:
  prometheus.yml: |
    # my global config
    global:
      scrape_interval:     15s # By default, scrape targets every 15 seconds.
      evaluation_interval: 15s # By default, scrape targets every 15 seconds.
      # scrape_timeout is set to the global default (10s).
      # Attach these labels to any time series or alerts when communicating with
      # external systems (federation, remote storage, Alertmanager).
      external_labels:
          monitor: 'faas-monitor'
    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
        - 'alert.rules'
    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'
        # Override the global default and scrape targets from this job every 5 seconds.
        scrape_interval: 5s
        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.
        static_configs:
          - targets: ['localhost:9090']
      - job_name: "gateway"
        scrape_interval: 5s
        dns_sd_configs:
          - names: ['gateway']
            port: 8080
            type: A
            refresh_interval: 5s
  alert.rules: |
    ALERT service_down
      IF up == 0
    ALERT APIHighInvocationRate
      IF sum ( rate(gateway_function_invocation_total{code="200"}[10s]) ) by (function_name) > 5
      FOR 5s
      LABELS {
        service = "gateway",
        severity = "major",
        value = "{{$value}}"
      }
      ANNOTATIONS {
        summary = "High invocation total on {{ $labels.instance }}",
        description =  "High invocation total on {{ $labels.instance }}"
      }
---
kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    app: alertmanager
  name: alertmanager-config
data:
  alertmanager.yml: |
    global:
      # The smarthost and SMTP sender used for mail notifications.
      smtp_smarthost: 'localhost:25'
      smtp_from: 'alertmanager@example.org'
      smtp_auth_username: 'alertmanager'
      smtp_auth_password: 'password'
      # The auth token for Hipchat.
      hipchat_auth_token: '1234556789'
      # Alternative host for Hipchat.
      hipchat_url: 'https://hipchat.foobar.org/'
    # The directory from which notification templates are read.
    templates:
    - '/etc/alertmanager/template/*.tmpl'
    # The root route on which each incoming alert enters.
    route:
      # The labels by which incoming alerts are grouped together. For example,
      # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
      # be batched into a single group.
      group_by: ['alertname', 'cluster', 'service']
      # When a new group of alerts is created by an incoming alert, wait at
      # least 'group_wait' to send the initial notification.
      # This way ensures that you get multiple alerts for the same group that start
      # firing shortly after another are batched together on the first
      # notification.
      group_wait: 5s
      # When the first notification was sent, wait 'group_interval' to send a batch
      # of new alerts that started firing for that group.
      group_interval: 10s
      # If an alert has successfully been sent, wait 'repeat_interval' to
      # resend them.
      repeat_interval: 30s
      # A default receiver
      receiver: scale-up
      # All the above attributes are inherited by all child routes and can
      # overwritten on each.
      # The child route trees.
      routes:
      - match:
          service: gateway
          receiver: scale-up
          severity: major
    # Inhibition rules allow to mute a set of alerts given that another alert is
    # firing.
    # We use this to mute any warning-level notifications if the same alert is
    # already critical.
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      # Apply inhibition if the alertname is the same.
      equal: ['alertname', 'cluster', 'service']
    receivers:
    - name: 'scale-up'
      webhook_configs:
        - url: http://gateway:8080/system/alert
          send_resolved: true
